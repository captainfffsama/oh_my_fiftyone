# -*- coding: utf-8 -*-
"""
@Author: captainsama
@Date: 2023-03-10 10:17:14
@LastEditors: captainsama tuanzhangsama@outlook.com
@LastEditTime: 2023-03-10 10:40:13
@FilePath: /dataset_manager/core/model/object_detection/chiebot_od.py
@Description:
"""
from typing import Union, List
from concurrent import futures

import numpy as np
import grpc
import cv2
import fiftyone.core.labels as focl
import fiftyone.core.models as focm

from .proto import dldetection_pb2
from .proto import dldetection_pb2_grpc

from core.utils import img2base64, tensor_proto2np
from .base_detection import ProtoBaseDetection, FOCMDefaultSetBase


class ChiebotObjectDetection(ProtoBaseDetection, FOCMDefaultSetBase,
                             focm.EmbeddingsMixin):

    def __init__(self, host, model_type: int = 1, embedding_imsize=(128, 128)):
        self.host = host
        self.model_type = model_type
        self._e_imsize = embedding_imsize
        self._last_embedding_img = None
        super().__init__()

    def __enter__(self):
        channel_opt = [('grpc.max_send_message_length', 512 * 1024 * 1024),
                       ('grpc.max_receive_message_length', 512 * 1024 * 1024)]
        self.channel = grpc.insecure_channel(self.host, options=channel_opt)
        self.stub = dldetection_pb2_grpc.AiServiceStub(self.channel)
        return self

    def __exit__(self, exc_type, exc_value, trace):
        self.channel.close()
        return super().__exit__(exc_type, exc_value, trace)

    def predict(self, img: Union[np.ndarray, str]) -> focl.Detections:
        imgbase64 = img2base64(img)
        # FIXME: 这里返回的时候归一化图片结果时,图片是忽略exif旋转信息
        if isinstance(img, str):
            img = cv2.imread(img,
                             cv2.IMREAD_IGNORE_ORIENTATION | cv2.IMREAD_COLOR)
        h, w = img.shape[:2]
        req = dldetection_pb2.DlRequest()
        req.imdata = imgbase64
        req.type = self.model_type
        response = self.stub.DlDetection(req)

        final_result = []

        for obj in response.results:
            final_result.append(
                focl.Detection(label=obj.classid,
                               bounding_box=[
                                   obj.rect.x / w,
                                   obj.rect.y / h,
                                   obj.rect.w / w,
                                   obj.rect.h / h,
                               ],
                               confidence=float(obj.score)))

        return focl.Detections(detections=final_result)

    def predict_all(
            self, imgs: Union[np.ndarray, List[str]]) -> List[focl.Detections]:
        if isinstance(imgs, np.ndarray) and len(imgs.shape) < 4:
            imgs = [imgs]
        if isinstance(imgs, np.ndarray) and len(imgs.shape) == 4:
            batch = imgs.shape[0]
            imgs = np.split(imgs, batch, axis=0)

        with futures.ThreadPoolExecutor(min(len(imgs), 48)) as exec:
            results = [x for x in exec.map(self.predict, imgs)]

        return results

    @property
    def has_embeddings(self):
        """Whether this instance can generate embeddings.

        This method returns ``False`` by default. Methods that can generate
        embeddings will override this via implementing the
        :class:`EmbeddingsMixin` interface.
        """
        return True

    def get_embeddings(self):
        """Returns the embeddings generated by the last forward pass of the
        model.

        By convention, this method should always return an array whose first
        axis represents batch size (which will always be 1 when :meth:`predict`
        was last used).

        Returns:
            a numpy array containing the embedding(s)
        """
        return self.embed(self._last_embedding_img)

    def embed(self,
              img: Union[np.ndarray, str],
              norm: bool = True) -> np.ndarray:
        """Generates an embedding for the given data.

        Subclasses can override this method to increase efficiency, but, by
        default, this method simply calls :meth:`predict` and then returns
        :meth:`get_embeddings`.

        Args:
            img: the data. See :meth:`predict` for details
            norm: bool=False
                if true,embedding will be standardized and L2 normalized

        Returns:
            a numpy array containing the embedding
        """
        # pylint: disable=no-member
        self._last_embedding_img = img
        imgbase64 = img2base64(img)

        req = dldetection_pb2.DlEmbeddingRequest()
        req.imdata = imgbase64
        req.imsize.extend(self._e_imsize)
        response = self.stub.DlEmbeddingGet(req)

        result = tensor_proto2np(response).flatten()
        if norm:
            result = (result - result.mean()) / result.std()
            return result / np.linalg.norm(result)
        return result

    def embed_all(self, imgs):
        """Generates embeddings for the given iterable of data.

        Subclasses can override this method to increase efficiency, but, by
        default, this method simply iterates over the data and applies
        :meth:`embed` to each.

        Args:
            args: an iterable of data. See :meth:`predict_all` for details

        Returns:
            a numpy array containing the embeddings stacked along axis 0
        """
        if isinstance(imgs, np.ndarray) and len(imgs.shape) < 4:
            imgs = [imgs]
        if isinstance(imgs, np.ndarray) and len(imgs.shape) == 4:
            batch = imgs.shape[0]
            imgs = np.split(imgs, batch, axis=0)

        with futures.ThreadPoolExecutor(min(len(imgs), 48)) as exec:
            results = [x for x in exec.map(self.embed, imgs)]

        return np.stack(results)